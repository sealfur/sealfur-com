---
title: "Human-centred design might destroy us"
author: "Joshua Kinal"
date: "2024-02-05"
tags: ["design", "responsibility", "human-centred"]
summary: "Human-centred design seems wonderful on paper. It’s helped lots of people and its benefits are so easy to see. Unfortunately, its popularity and wide-spread practice might lead to our extinction."
---

No doubt you’ve seen the term ‘human-centred’ used in relation to design, engineering or creation of technology. It turns up everywhere from [job ads](https://www.seek.com.au/%22human-centred%22-jobs) to relevancy-hungry [corporate rhetoric](https://www.mckinsey.com/search?q=human+centered&pageFilter=all&sort=default&start=1). Stanford University, where the term ‘human-centred design’ first came to prominence in the late 1950s now boasts an [Institute for Human-Centered Artificial Intelligence](https://hai.stanford.edu/navigate/welcome) [sic]. This concept has helped many people in their day-to-day lives. It sounds like a good thing, but it is slowly destroying us. Human-centred design largely ignores our responsibility to the future, favouring more immediate perceived benefits.

We should expect attitudes to have changed over the last seven decades. The concept’s origins as a more formalised practice, are attributed to Professor John E. Arnold. In 1958 he began teaching a [‘Creative Engineering’ summer course](https://inist.org/library/1959.John%20E%20Arnold.Creative%20Engineering.pdf). 66 years is a long time in the philosophy of technology, especially with the acceleration of technological advances.

If we go back around 70 years and look at engineering practices, we’ll see that engineering tended to dictate usability. The idea of usability informing engineering&mdash;that people’s physical abilities, their habits, desires and limitations should be primary considerations when designing technology&mdash;was largely unheard of. The arrogance that a creator requires to believe they have a better solution to a problem is the same arrogance that blames the user of a technology when it fails.

These attitudes still show up. In the late 1990s, when I started working with technology and customers, support teams regularly employed the acronym ‘<abbr title="problem exists between keyboard and chair">PEBKAC</abbr>’.[^1]

In 2010, when asked about the iPhone 4’s connectivity problems when held a certain way, [Steve Jobs responded](https://arstechnica.com/gadgets/2010/06/jobs-on-iphone-4-antenna-avoid-holding-it-in-this-way/):

> All phones have sensitive areas. Just avoid holding it in this way.

We certainly haven’t mastered human-centred design, even with its designation as an international standard: It’s included in the [ISO’s ‘Ergonomics of Human-System Interaction’ standard (ISO&nbsp;9241)](https://www.iso.org/standard/77520.html). Does that mean, though, that it should still be the standard we aim for in our practice?

We know so much more about the potential harm technology can bring and how that harm extends beyond human-centred problems (environmental pollution, species extinction threats, etc.). We have known this for decades. The truth is that human-centred design too often ignores the ecosystems we rely on to survive as a species. In practice it is biased towards finding short-term benefits for the people directly affected by the design and spends little-to-no effort on the contributions made to accelerating human extinction.

For the past few years we’ve seen articles about human-centred artificial intelligence (AI). The focus is on how AI will make things easier for humans and assist us in our work. But if we look beyond the immediate convenience, we see the [immense computer power required to build, maintain and improve the large language models](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/) (LLMs) that make the artificial intelligence possible. With that power consumption comes [unprecedented water use](https://fortune.com/2023/09/09/ai-chatgpt-usage-fuels-spike-in-microsoft-water-consumption/) and the [potential for huge carbon emissions](https://arxiv.org/pdf/1906.02243v1.pdf).

IBM have been at the forefront of artificial intelligence for decades. [Their explainer of human-centred AI](https://research.ibm.com/blog/what-is-human-centered-ai) focuses on utility: more immediate, trustworthy and insightful human-AI collaborations. Another part of their website summarises [IBM’s concerns for humans and AI to happily coexist](https://research.ibm.com/topics/human-centered-ai):

> Despite increasing levels of automation enabled by AI, the common thread to all of these systems is the human element: people are critical in the design, operation, and use of AI systems. We have a responsibility to ensure those systems operate transparently, act equitably, respect our privacy, and effectively serve people's needs.

This is in-step with common understanding of ‘human-centred’ as a concept, but the question remains as to whether this really puts the needs of humans at the centre of this work.

Victor Papanek’s _Design for the Real World_ (Second Edition, 1984) states our responsibility clearly in the title of its final chapter: ‘Design for Survival and Survival through Design’. It’s there that he writes about the three characteristics of design that provide its value ‘as the primary, underlying matrix of life’: that it should be integrated, comprehensive and anticipatory.

> Integrated, comprehensive, anticipatory design is the act of planning and shaping carried on across the various disciplines, an act continuously carried on at interfaces between them.

In an earlier chapter he had already outlined the path we were taking with technology and its relationship to commerce and economics:

> We are beginning to understand that the main challenge for our society no longer lies in the production of goods. Rather, we have to make choices that deal with "how good?" instead of "how much?"… But the margin is narrowing fast. With all these changes, the designer (as part of the multidisciplinary problem-solving team) can and must involve [themselves]. [They] may choose to do so for humanitarian reasons. Regardless of this, [they] will be forced to do so by the simple desire for survival within the not-too-distant future.

Human-centred design perpetuates hyperbolic discounting and normalcy bias. Through integrated, comprehensive and anticipatory design, we should be able to acknowledge these biases and take efforts to counteract them.

In human-centred design we are _still_ only looking at people’s existing needs, tending more towards the personal. To be truly integrated, comprehensive and anticipatory, the design of our technologies needs to include human survival _as part of_ the ecosystem that has supported us for so many millennia and the societies that help us support each other.

[^1]: I thought it was hilarious at the time. I was young and arrogant. My personal journey as a designer is one of learning humility and approaching each new scenario with curious ignorance.
